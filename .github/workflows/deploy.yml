name: Deploy

on:
  workflow_run:
    workflows: ["Build & test"]
    types:
      - completed

jobs:
  deploy:
    runs-on: ubuntu-20.04
    if: >-
      ${{ github.event.workflow_run.conclusion == 'success' && (
        github.actor == 'LukasKalbertodt' ||
        github.actor == 'JulianKniephoff' ||
        github.actor == 'lkiesow'
      ) }}
    steps:
    - uses: actions/checkout@v2

    # Unfortunately we cannot use `actions/download-artifact` here since that
    # only allows to download artifacts from the same run.
    - name: Download artifacts from build workflow
      uses: actions/github-script@v3.1.0
      with:
        script: |
          const artifacts = await github.actions.listWorkflowRunArtifacts({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id: ${{ github.event.workflow_run.id }},
          });
          const deployFiles = artifacts.data.artifacts
              .filter(a => a.name == "test-deployment-files")[0];
          const download = await github.actions.downloadArtifact({
              owner: context.repo.owner,
              repo: context.repo.repo,
              artifact_id: deployFiles.id,
              archive_format: 'zip',
          });

          const fs = require('fs');
          fs.writeFileSync('${{github.workspace}}/artifacts.zip', Buffer.from(download.data));

          // The artifact is not needed anymore
          github.actions.deleteArtifact({
              owner: context.repo.owner,
              repo: context.repo.repo,
              artifact_id: deployFiles.id,
          })

    # We could run `unzip -o` to overwrite all files, but that could easily lead
    # to security problems as the workflow creating the zip file can add
    # arbitrary files. Right now it does not matter as this workflow explicitly
    # only runs for trusted users, but being more careful here is better. So we
    # explicitly remove the file we expect to get overwriten.
    - name: extract artifacts
      run: |
        rm .deployment/templates/config.toml || true
        rm backend/logo-large.svg || true
        rm backend/logo-small.svg || true
        rm scripts/login-handler/login-handler.py || true
        unzip artifacts.zip

    - name: Prepare files for deployment
      run: |
        cp -v tobira .deployment/files/
        cp -v backend/logo-large.svg .deployment/files/
        cp -v backend/logo-small.svg .deployment/files/
        cp -v scripts/login-handler/login-handler.py .deployment/files/

    - name: prepare deploy key
      env:
        DEPLOY_KEY: ${{ secrets.DEPLOY_KEY }}
      run: |
        install -dm 700 ~/.ssh/
        echo "${DEPLOY_KEY}" > ~/.ssh/id_ed25519
        chmod 600 ~/.ssh/id_ed25519
        ssh-keyscan tobira.opencast.org >> ~/.ssh/known_hosts

    - name: install ansible postgres extensions
      run: ansible-galaxy collection install community.postgresql

    - name: deploy tobira branch
      working-directory: .deployment
      env:
        OPENCAST_ADMIN_PASSWORD: ${{ secrets.TOBIRA_OPENCAST_ADMIN_PASSWORD }}
      run: >
        ansible-playbook
        --private-key=~/.ssh/id_ed25519
        --extra-vars="deployid='$(cat ../deploy-id)'"
        -u github
        deploy.yml

    - name: comment on PR
      uses: actions/github-script@v3
      with:
        github-token: ${{secrets.GITHUB_TOKEN}}
        script: |
          const fs = require('fs');
          const deploy_id = fs.readFileSync('${{github.workspace}}/deploy-id', 'utf8').trim();
          if (deploy_id.startsWith('pr')) {
              const body = `ðŸš€ This PR was deployed at https://${deploy_id}.tobira.opencast.org. `
                  + `The deployment will be updated whenever someone pushes onto this PR's branch.`;
              const issue_number = Number(deploy_id.substring(2));

              // Check if we commented before
              let page = 0;
              let commentedAlready = false;

              // In theory we don't need this upper limit of 20, but I am really uncomfortable
              // having a potentially infinite loop in here. So I rather have this artificial
              // upper limit. The worst that can happen is that this actions adds a second
              // comment.
              for (let page = 0; page < 20; page++) {
                  const comments = await github.issues.listComments({
                      issue_number,
                      owner: context.repo.owner,
                      repo: context.repo.repo,
                      per_page: 100,
                      page,
                  });

                  if (comments.data.length == 0) {
                      break;
                  }

                  if (comments.data.some(c => c.body == body)) {
                      console.log("Found an identical comment: will not comment again.")
                      commentedAlready = true;
                      break;
                  }
              }

              if (!commentedAlready) {
                  await github.issues.createComment({
                      issue_number,
                      owner: context.repo.owner,
                      repo: context.repo.repo,
                      body,
                  })
              }
          }
